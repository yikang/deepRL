{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.2.0-py3-none-any.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: cloudpickle in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Collecting torch>=1.8.1\n",
      "  Downloading torch-1.9.1-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4 MB 37 kB/s s eta 0:00:01     |███████████████████████████████▎| 812.4 MB 12.3 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.2.4)\n",
      "Requirement already satisfied: gym>=0.17 in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.20.0)\n",
      "Requirement already satisfied: pillow in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (8.2.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.6.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.3.56-cp38-cp38-manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.9 MB 12.3 MB/s eta 0:00:01   |█████▊                          | 8.9 MB 9.3 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/steven/anaconda3/lib/python3.8/site-packages (from stable-baselines3[extra]) (5.8.0)\n",
      "Collecting atari-py~=0.2.0\n",
      "  Downloading atari_py-0.2.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/steven/anaconda3/lib/python3.8/site-packages (from atari-py~=0.2.0->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.18.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.40.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/steven/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/steven/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/steven/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/steven/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/steven/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/steven/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/steven/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/steven/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /home/steven/anaconda3/lib/python3.8/site-packages (from torch>=1.8.1->stable-baselines3[extra]) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/steven/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/steven/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/steven/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/steven/anaconda3/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/steven/anaconda3/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2021.1)\n",
      "Installing collected packages: torch, stable-baselines3, opencv-python, atari-py\n",
      "Successfully installed atari-py-0.2.9 opencv-python-4.5.3.56 stable-baselines3-1.2.0 torch-1.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7776, 0.0622, 0.8918],\n",
      "        [0.3127, 0.3568, 0.0381],\n",
      "        [0.8442, 0.1254, 0.2274],\n",
      "        [0.0355, 0.3835, 0.8980],\n",
      "        [0.4898, 0.7543, 0.2700]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify pyTorch\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CartPole-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:23.0\n",
      "Episode:2 Score:34.0\n",
      "Episode:3 Score:13.0\n",
      "Episode:4 Score:30.0\n",
      "Episode:5 Score:28.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Environment\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-push cart to left, 1-push cart to the right\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training','Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1,tensorboard_log=log_path) # multi-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 491  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 4    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008528819 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00276     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.47        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007331223 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.0379      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007501369 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008326678 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067115184 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 66.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004734331 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 706          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052010906 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 61.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036746871 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 77.2         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000728    |\n",
      "|    value_loss           | 74.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 707          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027007211 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    value_loss           | 70           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd290b711c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('PPO_model', env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info [{'TimeLimit.truncated': True, 'terminal_observation': array([-0.28821322, -0.03333642,  0.02086917, -0.00320131], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs) # use model to decide action\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding a callback to the training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=190, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Training', 'Saved Models', 'best_model')\n",
    "model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch=[dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dqn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(dqn_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
